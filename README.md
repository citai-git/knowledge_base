# Welcome to the CitAI knowledge base

## Table of Contents  
[Artificial general intelligence](#artificial-general-intelligence) \
[Associative learning](#associative-learning) \
[Category theory in AI](#category-theory-in-ai) \
[Deep learning](#deep-learning) \
[Free Energy principle](#free-energy-principle)  \
[Medical imaging](#medical-imaging) \
[Reinforcement learning](#reinforcement-learning) \
[Representation learning](representation-learning) \
[Statistical methods in AI](#statistical-methods-in-ai) \


[Maths resources](#maths) \
​	[Category theory](#category-theory) \
​	[Groups & grouplike structures](#groups-&-grouplike-structures) \


[Neurips2020](#neurips2020) \


<a name="artificial-general-intelligence"/>
## Artificial general intelligence





<a name="associative-learning"/>
## Associative learning







<a name="category-theory-in-ai"/>
## Category theory in AI







<a name="deep-learning"/>
## Deep learning





<a name="free-energy-principle"/>
## Free Energy Principle

#### [Action and Perception as Divergence Minimization](https://arxiv.org/abs/2009.01791)

**authors:** Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston, Nicolas Heess.

**year:** 2020.

**abstract:**  We introduce a unified objective for action and perception of intelligent agents. Extending representation learning and control, we minimize the joint divergence between the world and a target distribution. Intuitively, such agents use perception to align their beliefs with the world, and use actions to align the world with their beliefs. Minimizing the joint divergence to an expressive target maximizes the mutual information between the agent's representations and inputs, thus inferring representations that are informative of past inputs and exploring future inputs that are informative of the representations. This lets us derive intrinsic objectives, such as representation learning, information gain, empowerment, and skill discovery from minimal assumptions. Moreover, interpreting the target distribution as a latent variable model suggests expressive world models as a path toward highly adaptive agents that seek large niches in their environments, while rendering task rewards optional. The presented framework provides a common language for comparing a wide range of objectives, facilitates understanding of latent variables for decision making, and offers a recipe for designing novel objectives. We recommend deriving future agent objectives from the joint divergence to facilitate comparison, to point out the agent's target distribution, and to identify the intrinsic objective terms needed to reach that distribution.





<a name="medical-imaging"/>
## Medical imagining




<a name="reinforcement-learning"/>
## Reinforcement learning







<a name="representation-learning"/>
## Representation learning





<a name="statistical-methods-in-ai"/>
## Statistical methods in AI






<a name="maths"/>
## Maths



<a name="category-theory"/>
### Category theory







<a name="groups-&-grouplike-structures"/>
### Groups & grouplike structures





<a name="neurips2020"/>
## NEURIPS 2020 papers

### Graphs

- #### [CASTLE: Regularization via Auxiliary Causal Graph Discovery](https://proceedings.neurips.cc/paper/2020/hash/1068bceb19323fe72b2b344ccf85c254-Abstract.html)

- #### [Graphon Neural Networks and the Transferability of Graph Neural Networks](https://proceedings.neurips.cc/paper/2020/hash/12bcd658ef0a540cabc36cdf2b1046fd-Abstract.html)

- #### [Pointer graph networks](https://proceedings.neurips.cc/paper/2020/hash/176bf6219855a6eb1f3a30903e34b6fb-Abstract.html)

- #### [Multimodal Graph Networks for Compositional Generalization in Visual Question Answering](https://proceedings.neurips.cc/paper/2020/hash/1fd6c4e41e2c6a6b092eb13ee72bce95-Abstract.html)

- #### [Learning Dynamic Belief Graphs to Generalize on Text-Based Games](https://proceedings.neurips.cc/paper/2020/hash/1fc30b9d4319760b04fab735fbfed9a9-Abstract.html)

- #### [Learning Graph Structure With A Finite-State Automaton Layer](https://proceedings.neurips.cc/paper/2020/hash/1fdc0ee9d95c71d73df82ac8f0721459-Abstract.html)

- #### [A Graph Similarity for Deep Learning](https://proceedings.neurips.cc/paper/2020/file/0004d0b59e19461ff126e3a08a814c33-Paper.pdf)

- #### [Neural Message Passing for Multi-Relational Ordered and Recursive Hypergraphs](https://proceedings.neurips.cc/paper/2020/hash/217eedd1ba8c592db97d0dbe54c7adfc-Abstract.html)

- #### [How hard is to distinguish graphs with graph neural networks?](https://proceedings.neurips.cc/paper/2020/hash/23685a2431acad7789c1e3d43ea1522c-Abstract.html)

- #### [Natural Graph Networks](https://proceedings.neurips.cc/paper/2020/hash/2517756c5a9be6ac007fe9bb7fb92611-Abstract.html)

- #### [Towards Deeper Graph Neural Networks with Differentiable Group Normalization](https://proceedings.neurips.cc/paper/2020/hash/33dd6dba1d56e826aac1cbf23cdcca87-Abstract.html)

- #### [Towards practical differentially private causal graph discovery](https://proceedings.neurips.cc/paper/2020/hash/3b13b1eb44b05f57735764786fab9c2c-Abstract.html)

- #### [Graph Meta Learning via Local Subgraphs](https://proceedings.neurips.cc/paper/2020/hash/412604be30f701b1b1e3124c252065e6-Abstract.html)

- #### [Bandit Samplers for Training Graph Neural Networks](https://proceedings.neurips.cc/paper/2020/hash/4cea2358d3cc5f8cd32397ca9bc51b94-Abstract.html)

- #### [Community detection in sparse time-evolving graphs with a dynamical Bethe-Hessian](https://proceedings.neurips.cc/paper/2020/hash/54391c872fe1c8b4f98095c5d6ec7ec7-Abstract.html)

- #### [Graph Geometry Interaction Learning](https://proceedings.neurips.cc/paper/2020/hash/551fdbb810aff145c114b93867dd8bfd-Abstract.html)

- #### [Implicit Graph Neural Networks](https://proceedings.neurips.cc/paper/2020/hash/8b5c8441a8ff8e151b191c53c1842a38-Abstract.html)


### Transfer learning

- #### [A Combinatorial Perspective on Transfer Learning](https://proceedings.neurips.cc/paper/2020/hash/0a3b6f64f0523984e51323fe53b8c504-Abstract.html)

- #### [What is being transferred in transfer learning?](https://proceedings.neurips.cc/paper/2020/hash/0607f4c705595b911a4f3e7a127b44e0-Abstract.html)

- #### [On the Theory of Transfer Learning: The Importance of Task Diversity](https://proceedings.neurips.cc/paper/2020/hash/59587bffec1c7846f3e34230141556ae-Abstract.html)


### Reinforcement learning

- #### [Reinforcement Learning with Combinatorial Actions: An Application to Vehicle Routing](https://proceedings.neurips.cc/paper/2020/hash/06a9d51e04213572ef0720dd27a84792-Abstract.html)

- #### [A Unifying View of Optimism in Episodic Reinforcement Learning](https://proceedings.neurips.cc/paper/2020/hash/0f0e13216262f4a201bec128044dd30f-Abstract.html)

- #### [Reinforcement Learning for Control with Multiple Frequencies](https://proceedings.neurips.cc/paper/2020/hash/216f44e2d28d4e175a194492bde9148f-Abstract.html)

- #### [Multi-Task Reinforcement Learning with Soft Modularization](https://proceedings.neurips.cc/paper/2020/hash/32cfdce9631d8c7906e8e9d6e68b514b-Abstract.html)

- #### [Neurosymbolic Reinforcement Learning with Formally Verified Exploration](https://proceedings.neurips.cc/paper/2020/hash/448d5eda79895153938a8431919f4c9f-Abstract.html)


### Objects

 - #### [Learning About Objects by Learning to Interact with Them](https://proceedings.neurips.cc/paper/2020/hash/291597a100aadd814d197af4f4bab3a7-Abstract.html)

- #### [Continuous Object Representation Networks: Novel View Synthesis without Target View Supervision](https://proceedings.neurips.cc/paper/2020/hash/43a7c24e2d1fe375ce60d84ac901819f-Abstract.html)


### Representations

- #### [Learning Disentangled Representations of Videos with Missing Data](https://proceedings.neurips.cc/paper/2020/hash/24f2f931f12a4d9149876a5bef93e96a-Abstract.html)

- #### [ICAM: Interpretable Classification via Disentangled Representations and Feature Attribution Mapping](https://proceedings.neurips.cc/paper/2020/hash/56f9f88906aebf4ad985aaec7fa01313-Abstract.html)

- #### [Self-Supervised Relational Reasoning for Representation Learning](https://proceedings.neurips.cc/paper/2020/hash/29539ed932d32f1c56324cded92c07c2-Abstract.html)

- #### [Unsupervised Learning of Dense Visual Representations](https://proceedings.neurips.cc/paper/2020/hash/3000311ca56a1cb93397bc676c0b7fff-Abstract.html)

- #### [Neural Star Domain as Primitive Representation](https://proceedings.neurips.cc/paper/2020/hash/59a3adea76fadcb6dd9e54c96fc155d1-Abstract.html)


### Attention, transformers and language

- #### [Auto Learning Attention](https://proceedings.neurips.cc/paper/2020/hash/103303dd56a731e377d01f6a37badae3-Abstract.html) 

- #### [MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers](https://proceedings.neurips.cc/paper/2020/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)

- #### [Towards Interpretable Natural Language Understanding with Explanations as Latent Variables](https://proceedings.neurips.cc/paper/2020/hash/4be2c8f27b8a420492f2d44463933eb6-Abstract.html)

- #### [Hierarchical Poset Decoding for Compositional Generalization in Language](https://proceedings.neurips.cc/paper/2020/hash/4d7e0d72898ae7ea3593eb5ebf20c744-Abstract.html)


### Brain learning

- #### [Attention-Gated Brain Propagation: How the brain can implement reward-based error backpropagation](https://proceedings.neurips.cc/paper/2020/hash/1abb1e1ea5f481b589da52303b091cbb-Abstract.html)

- #### [Inferring learning rules from animal decision-making](https://proceedings.neurips.cc/paper/2020/hash/234b941e88b755b7a72a1c1dd5022f30-Abstract.html)

- #### [Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE](https://proceedings.neurips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html)


### Other

- #### [An Unsupervised Information-Theoretic Perceptual Quality Metric](https://proceedings.neurips.cc/paper/2020/hash/00482b9bed15a272730fcb590ffebddd-Abstract.html)

- #### [Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability](https://proceedings.neurips.cc/paper/2020/hash/0d770c496aa3da6d2c3f2bd19e7b9d6b-Abstract.html) *Christopher Frye, Colin Rowat, Ilya Feige*

- #### [Benchmarking Deep Inverse Models over time, and the Neural-Adjoint method](https://proceedings.neurips.cc/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html) *Simiao Ren, Willie Padilla, Jordan Malof* 

- #### [Backpropagating Linearly Improves Transferability of Adversarial Examples](https://proceedings.neurips.cc/paper/2020/hash/00e26af6ac3b1c1c49d7c3d79c60d000-Abstract.html) *Yiwen Guo, Qizhang Li, Hao Chen*

- #### [Algorithmic recourse under imperfect causal knowledge: a probabilistic approach](https://proceedings.neurips.cc/paper/2020/hash/02a3c7fb3f489288ae6942498498db20-Abstract.html) *Amir-Hossein Karimi, Bodo Julius von Kügelgen, Bernhard Schölkopf, Isabel Valera*

- #### [Quantitative Propagation of Chaos for SGD in Wide Neural Networks](https://proceedings.neurips.cc/paper/2020/hash/02e74f10e0327ad868d138f2b4fdd6f0-Abstract.html) *Valentin De Bortoli, Alain Durmus, Xavier Fontaine, Umut Simsekli*

- #### [Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time](https://proceedings.neurips.cc/paper/2020/hash/05128e44e27c36bdba71221bfccf735d-Abstract.html) *Kai Han, zongmai Cao, Shuang Cui, Benwei Wu*

- #### [Flows for simultaneous manifold learning and density estimation](https://proceedings.neurips.cc/paper/2020/hash/051928341be67dcba03f0e04104d9047-Abstract.html) *Johann Brehmer, Kyle Cranmer* 

- #### [Online Agnostic Boosting via Regret Minimization](https://proceedings.neurips.cc/paper/2020/hash/07168af6cb0ef9f78dae15739dd73255-Abstract.html) *Nataly Brukhim, Xinyi Chen, Elad Hazan, Shay Moran*

- #### [Belief Propagation Neural Networks](https://proceedings.neurips.cc/paper/2020/hash/07217414eb3fbe24d4e5b6cafb91ca18-Abstract.html) *Jonathan Kuck, Shuvam Chakraborty, Hao Tang, Rachel Luo, Jiaming Song, Ashish Sabharwal, Stefano Ermon*

- #### [Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian](https://proceedings.neurips.cc/paper/2020/hash/08425b881bcde94a383cd258cea331be-Abstract.html) *Jack Parker-Holder, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair Letcher, Alexander Peysakhovich, Aldo Pacchiano, Jakob Foerster*

- #### [Towards Better Generalization of Adaptive Gradient Methods](https://proceedings.neurips.cc/paper/2020/hash/08fb104b0f2f838f3ce2d2b3741a12c2-Abstract.html) *Yingxue Zhou, Belhal Karimi, Jinxing Yu, Zhiqiang Xu, Ping Li*

- #### [Learning Guidance Rewards with Trajectory-space Smoothing](https://proceedings.neurips.cc/paper/2020/hash/0912d0f15f1394268c66639e39b26215-Abstract.html) *Tanmay Gangwani, Yuan Zhou, Jian Peng*

- #### [Deep Structural Causal Models for Tractable Counterfactual Inference](https://proceedings.neurips.cc/paper/2020/hash/0987b8b338d6c90bbedd8631bc499221-Abstract.html) *Nick Pawlowski, Daniel Coelho de Castro, Ben Glocker*

- #### [Better Set Representations For Relational Reasoning](https://proceedings.neurips.cc/paper/2020/hash/09ccf3183d9e90e5ae1f425d5f9b2c00-Abstract.html) *Qian Huang, Horace He, Abhay Singh, Yan Zhang, Ser Nam Lim, Austin R. Benson*
